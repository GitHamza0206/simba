# config.yaml
#TODO: connect to config.py

project:
  name: "Simba"
  version: "1.0.0"
  api_version: "/api/v1"

paths:
  base_dir: null  # Will be set programmatically
  markdown_dir: "markdown"
  faiss_index_dir: "vector_stores/faiss_index"
  vector_store_dir: "vector_stores"

llm:
  provider: "openai"
  model_name: "gpt-4o"
  temperature: 0.0
  max_tokens: null
  streaming: true
  additional_params: {}

embeddings:
  provider: "huggingface"
  model_name: "BAAI/llm-embedder"
  device: "mps"
  additional_params: {}

vector_store:
  provider: "faiss"
  collection_name: "migi_collection"
  additional_params: {}

chunking:
  chunk_size: 512
  chunk_overlap: 200

retrieval:
  k: 5