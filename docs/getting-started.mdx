---
title: Getting Started
description: Install and configure Simba for your environment
icon: "ðŸš€"
---

# Getting Started

This guide will help you set up Simba in your environment. Follow these steps to install, configure, and run Simba for your knowledge management needs.

## Installation Options

You have a few options for installing Simba:

### 1. Install Simba Core (pip)

The easiest way to get started is to install the core Simba package using pip:

```bash
pip install simba-core
```

### 2. Clone from GitHub (for development)

For development or if you want to modify Simba:

```bash
git clone https://github.com/GitHamza0206/simba.git
cd simba
poetry config virtualenvs.in-project true
poetry install
source .venv/bin/activate
```

### 3. Using Docker (for deployment)

See the [Deployment Guide](deployment.md) for Docker instructions.

## Configuration

### Environment Variables

Create a `.env` file in the root directory and add your environment variables:

```bash
OPENAI_API_KEY=your_openai_api_key
REDIS_HOST=localhost
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1
```

### System Configuration

Review and modify `config.yaml` in the root directory to adjust settings like LLM provider, embedding model, vector store, etc:

```yaml
# config.yaml

project:
  name: "Simba"
  version: "1.0.0"
  api_version: "/api/v1"

paths:
  base_dir: null  # Will be set programmatically
  faiss_index_dir: "vector_stores/faiss_index"
  vector_store_dir: "vector_stores"

llm:
  provider: "openai"
  model_name: "gpt-4o-mini"
  temperature: 0.0
  max_tokens: null
  streaming: true
  additional_params: {}

embedding:
  provider: "huggingface"
  model_name: "BAAI/bge-base-en-v1.5"
  device: "mps"
  additional_params: {}

vector_store:
  provider: "faiss"
  collection_name: "simba_collection"
  additional_params: {}

chunking:
  chunk_size: 512
  chunk_overlap: 200

retrieval:
  method: "hybrid"
  k: 5
  params:
    score_threshold: 0.5
    prioritize_semantic: true
    weights: [0.7, 0.3]
    reranker_model: colbert
    reranker_threshold: 0.7

database:
  provider: litedb
  additional_params: {}

celery: 
  broker_url: ${CELERY_BROKER_URL:-redis://redis:6379/0}
  result_backend: ${CELERY_RESULT_BACKEND:-redis://redis:6379/1}
```

## Running Simba

Start the Simba components:

```bash
simba server  # Start the backend API server
simba front   # Start the frontend UI
simba parsers # Start the document parsing service
```

Now you should be able to access the Simba frontend in your browser (usually at `http://localhost:3000` if running locally).

## Next Steps

After installation, you can:

* **Explore the Simba UI** to upload and manage documents
* **Try the [Simba SDK](sdk_reference.md)** to interact programmatically with your knowledge base
* **Check out the examples** for demonstrations of common use cases
* **Connect Simba** to your existing RAG applications

For deployment options including cloud and self-hosted setups, see the [Deployment Guide](deployment.md).